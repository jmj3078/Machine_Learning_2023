{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mxs6GT7YT0S-"
      },
      "source": [
        "![python image2](https://user-images.githubusercontent.com/68190553/117823565-9345b100-b2a8-11eb-8b06-cfbe5511b053.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "xUBNg4SF0ukS"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "9RjCg3-i0x-Q"
      },
      "outputs": [],
      "source": [
        "# 문제 1: ResNet18.ipynb 파일을 참고하여 ResNet34를 위한 Basic Block을 설계해보세요.\n",
        "\n",
        "# ResNet18과 ResNet34에서 사용되는 BasicBlock은 그 구조가 똑같기 때문에,\n",
        "# ResNet18에서 사용했던 BasicBlock class를 그대로 사용했습니다.\n",
        "class BasicBlock(tf.keras.layers.Layer):\n",
        "    def __init__(self, in_filters, out_filters, downsample=False):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.pad1 = tf.keras.layers.ZeroPadding2D((1,1))\n",
        "\n",
        "        self.relu = tf.keras.layers.ReLU()\n",
        "        self.conv2 = tf.keras.layers.Conv2D(out_filters, (3,3), strides=(1,1))\n",
        "        \n",
        "        self.batch_norm1 = tf.keras.layers.BatchNormalization()\n",
        "        self.batch_norm2 = tf.keras.layers.BatchNormalization()\n",
        "\n",
        "        # downsample이 활성화 될 시, 샘플 사이즈 절반으로 축소\n",
        "        # block c, block d, block e에서만 한번씩 실행시켜주면 됩니다.\n",
        "        if downsample:\n",
        "            self.conv1 = tf.keras.layers.Conv2D(out_filters, (3,3), strides=(2,2))\n",
        "            self.downsample = tf.keras.layers.Conv2D(out_filters, (1,1), strides=(2,2))\n",
        "        else:\n",
        "            self.conv1 = tf.keras.layers.Conv2D(out_filters, (3,3), strides=(1,1))\n",
        "            self.downsample = None\n",
        "        \n",
        "        # input fiiter 크기와 output filter 크기가 다를 때 Conv2D를 사용해서 그 크기를 맞춰줌\n",
        "        # 새로운 블록으로 들어올 때 input filter 크기와 output filter크기를 다르게 설정해서 활성화 시켜줍니다.\n",
        "        if in_filters == out_filters:\n",
        "            self.channel_shaper = None\n",
        "        else:\n",
        "            self.channel_shaper = tf.keras.layers.Conv2D(out_filters, (1,1), strides=(1,1))\n",
        "\n",
        "\n",
        "    def __call__(self, inputs):\n",
        "        identity = inputs\n",
        "        out = self.pad1(inputs)\n",
        "        out = self.conv1(out)\n",
        "        out = self.batch_norm1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.pad1(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.batch_norm2(out)\n",
        "        # 잔차 계산을 통해 전달\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(inputs)\n",
        "        if self.channel_shaper is not None:\n",
        "            identity = self.channel_shaper(identity)\n",
        "        # output과 잔차를 더해줌\n",
        "        out += identity \n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "SG_3VNPo01gg"
      },
      "outputs": [],
      "source": [
        "# 문제 2: 위에서 만든 Basic Block을 기반으로 ResNet34 모델을 정의하세요.\n",
        "class ResNet34(tf.keras.Model):\n",
        "    def __init__(self, num_classes) -> None:\n",
        "        super(ResNet34, self).__init__()\n",
        "        self.pad3 = tf.keras.layers.ZeroPadding2D((3,3))\n",
        "        self.pad1 = tf.keras.layers.ZeroPadding2D((1,1))\n",
        "        self.conv1 = tf.keras.layers.Conv2D(64, kernel_size=(7,7), strides=(2,2))\n",
        "        self.pool = tf.keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2))\n",
        "        self.batch_norm = tf.keras.layers.BatchNormalization()\n",
        "        self.relu = tf.keras.layers.ReLU()\n",
        "\n",
        "        # build_layer 함수를 통해서 각각 3번, 4번, 6번, 6번 BasicBlock을 쌓습니다.\n",
        "        # block b에서는 샘플의 크기가 변하지 않고, block c, d, e에서만 절반으로 줄어들어야 하기 때문에\n",
        "        # conv라는 옵션을 통해 downsampling block 추가 유무를 결정합니다.\n",
        "        self.block_b = self.build_layers(64, 64, 3, conv=False) \n",
        "        self.block_c = self.build_layers(64, 128, 4, conv=True)\n",
        "        self.block_d = self.build_layers(128, 256, 6, conv=True)\n",
        "        self.block_e = self.build_layers(256, 512, 6, conv=True)\n",
        "\n",
        "        # 마지막 단계에서 Global Average Pooling 실시\n",
        "        self.Avgpooling = tf.keras.layers.GlobalAveragePooling2D()\n",
        "        # Fully connected layer형성을 위한 flatten()\n",
        "        self.flat = tf.keras.layers.Flatten()\n",
        "        # num_class수 만큼의 output 반환. 활성화 함수 softmax사용\n",
        "        self.dense = tf.keras.layers.Dense(num_classes, activation=\"softmax\")\n",
        "\n",
        "    def build_layers(self, in_filters, out_filters, num_blocks, conv=False):\n",
        "        # layer 리스트에 필요한 layer들을 append한 다음 한번에 tf.keras.Sequential로 레이어를 반환합니다.\n",
        "        layers= []\n",
        "\n",
        "        # conv 옵션이 활성화 될 경우에는 downsampling=True를 가장 첫 BasicBlock에서 활성시켜야 합니다.\n",
        "        # 활성화 될 시 stride의 크기가 2로 설정되어 샘플의 크기가 절반으로 줄어듭니다.\n",
        "        # 첫 BasicBlock의 경우 필터 크기의 변환도 실행해야 하기 때문에, in_filters와 out_filters를 입력값으로 줍니다.\n",
        "        if conv :\n",
        "            layers.append(BasicBlock(in_filters, out_filters, downsample=True))\n",
        "        else : \n",
        "            layers.append(BasicBlock(in_filters, out_filters, downsample=False))\n",
        "        # 두번째 블록부터는 in_filter와 out_filter의 크기가 같습니다.\n",
        "        # 따라서 out_filter값을 in_filter, out_filter에 넣어서 BasicBlock을 쌓습니다.\n",
        "        for i in range(num_blocks-1):\n",
        "            layers.append(BasicBlock(out_filters, out_filters, downsample=False))\n",
        "        \n",
        "        # 쌓인 레이어들을 한번에 Sequential을 통해 반환합니다.\n",
        "        return tf.keras.Sequential(layers)\n",
        "\n",
        "    \n",
        "    def call(self, x):\n",
        "        # block A를 구현합니다.\n",
        "        out = self.conv1(x) # kernel size 7,7, strides=2, 샘플 크기가 절반으로 줄어듭니다. 64개의 채널을 가집니다.\n",
        "        out = self.pad3(out) # kernel size 3,3, zero padding\n",
        "        out = self.batch_norm(out) \n",
        "        out = self.relu(out)\n",
        "        out = self.pool(out) # kenrel size 3,3 strides=2, 샘플 크기가 절반으로 줄어듭니다.\n",
        "        out = self.pad1(out) # kernel size 1,1 로 zero padding\n",
        "\n",
        "        out = self.block_b(out) # input channel 수 64, output channel 수 64\n",
        "        out = self.block_c(out) # input channel 수 64, output channel 수 128\n",
        "        out = self.block_d(out) # input channel 수 128, output channel 수 256\n",
        "        out = self.block_e(out) # input channel 수 256, output channel 수 512\n",
        "\n",
        "        out = self.Avgpooling(out) # global average pooling \n",
        "        out = self.flat(out) # flatten layer\n",
        "        out = self.dense(out) # Fully connected layer형성, num_class수 만큼의 output layer반환. 활성화 함수 softmax사용\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "SOEhuiMb04yl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22a39fe1-3cda-4f1b-aec4-a95f20c97239"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"res_net34_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " zero_padding2d_219 (ZeroPad  multiple                 0         \n",
            " ding2D)                                                         \n",
            "                                                                 \n",
            " zero_padding2d_220 (ZeroPad  multiple                 0         \n",
            " ding2D)                                                         \n",
            "                                                                 \n",
            " conv2d_459 (Conv2D)         multiple                  9472      \n",
            "                                                                 \n",
            " max_pooling2d_13 (MaxPoolin  multiple                 0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_399 (Ba  multiple                 256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " re_lu_206 (ReLU)            multiple                  0         \n",
            "                                                                 \n",
            " sequential_40 (Sequential)  (None, 10, 10, 64)        223104    \n",
            "                                                                 \n",
            " sequential_41 (Sequential)  (None, 5, 5, 128)         1135872   \n",
            "                                                                 \n",
            " sequential_42 (Sequential)  (None, 3, 3, 256)         6897152   \n",
            "                                                                 \n",
            " sequential_43 (Sequential)  (None, 2, 2, 512)         27556864  \n",
            "                                                                 \n",
            " global_average_pooling2d_9   multiple                 0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         multiple                  0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             multiple                  5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 35,827,850\n",
            "Trainable params: 35,806,474\n",
            "Non-trainable params: 21,376\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Do not Touch!\n",
        "model = ResNet34(num_classes=10)\n",
        "model.build(input_shape=[None, 28,28,3])\n",
        "model.compile(optimizer='adam',\n",
        "             loss='categorical_crossentropy',\n",
        "             metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "EPQClJoKIrZ4"
      },
      "outputs": [],
      "source": [
        "# Do not Touch!\n",
        "# Loss Function을 변수로 정의\n",
        "import tensorflow as tf\n",
        "\n",
        "loss_function = tf.keras.losses.CategoricalCrossentropy()\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "train_acc = tf.keras.metrics.CategoricalAccuracy()\n",
        "test_acc = tf.keras.metrics.CategoricalAccuracy() \n",
        "val_acc = tf.keras.metrics.CategoricalAccuracy() \n",
        "\n",
        "train_loss = tf.keras.metrics.Mean()\n",
        "test_loss = tf.keras.metrics.Mean()\n",
        "val_loss = tf.keras.metrics.Mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "E64I3o93juo7"
      },
      "outputs": [],
      "source": [
        "# Do not Touch!\n",
        "@tf.function\n",
        "def train_step(images, labels):\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(images)\n",
        "        loss = loss_function(labels, predictions)\n",
        "    \n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "    train_loss.update_state(loss)\n",
        "    train_acc.update_state(labels, predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "GYtI4l9WHxqB"
      },
      "outputs": [],
      "source": [
        "# Do not Touch!\n",
        "@tf.function\n",
        "def test_step(images, labels):\n",
        "    predictions = model(images)\n",
        "    loss = loss_function(labels, predictions)\n",
        "    \n",
        "    test_loss.update_state(loss)\n",
        "    test_acc.update_state(labels, predictions)\n",
        "\n",
        "    return labels, predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "YnMwUGY8L2nJ"
      },
      "outputs": [],
      "source": [
        "# Do not Touch!\n",
        "@tf.function\n",
        "def val_step(images, labels):\n",
        "    predictions = model(images)\n",
        "    loss = loss_function(labels, predictions)\n",
        "    \n",
        "    val_loss.update_state(loss)\n",
        "    val_acc.update_state(labels, predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "iGE22StzjzA7"
      },
      "outputs": [],
      "source": [
        "# Do not Touch!\n",
        "import math \n",
        "\n",
        "class generator(tf.keras.utils.Sequence):\n",
        "    def __init__(self, x, y, batch_size, shuffle =True):\n",
        "        self.x = x.astype(np.float32)\n",
        "        self.y = y\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return math.ceil(len(self.x) / self.batch_size)\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        self.indices = np.arange(len(self.x))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indices)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        indices = self.indices[index*self.batch_size:(index+1)*self.batch_size]\n",
        "        return self.x[indices], self.y[indices]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "Xekl6vPhIyxG"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "\n",
        "# CIFAR-10 데이터셋 불러오기\n",
        "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
        "\n",
        "# 문제 3 (Optional): 정확도를 올리기 위한 데이터 전처리를 수행하셔도 됩니다.\n",
        "\n",
        "# 레이블을 범주형으로 인코딩\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "ZqJEfQfyHn2s"
      },
      "outputs": [],
      "source": [
        "# Do not Touch!\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_images, val_images, train_labels, val_labels = train_test_split(train_images, train_labels, test_size=0.2, random_state=10)\n",
        "\n",
        "train_ds = generator(train_images, train_labels, batch_size=32)\n",
        "val_ds = generator(val_images, val_labels, batch_size=32)\n",
        "test_ds = generator(test_images, test_labels, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCKmzVzbhQME",
        "outputId": "a55f0ca5-1476-4bd9-cf1a-c2ceb8475a40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch0 Training\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1250/1250 [01:43<00:00, 12.05it/s]\n",
            "100%|██████████| 313/313 [00:05<00:00, 52.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "에포크: 1, 손실: 4.55302, 정확도: 28.26%, 테스트 손실: 1.73243, 테스트 정확도: 36.53%\n",
            "✅ Model Loss Updated\n",
            "Epoch1 Training\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1250/1250 [01:05<00:00, 19.06it/s]\n",
            "100%|██████████| 313/313 [00:04<00:00, 76.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "에포크: 2, 손실: 1.56000, 정확도: 42.79%, 테스트 손실: 1.45513, 테스트 정확도: 47.20%\n",
            "✅ Model Loss Updated\n",
            "Epoch2 Training\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1250/1250 [01:06<00:00, 18.87it/s]\n",
            "100%|██████████| 313/313 [00:04<00:00, 75.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "에포크: 3, 손실: 1.42473, 정확도: 48.56%, 테스트 손실: 1.43620, 테스트 정확도: 49.13%\n",
            "✅ Model Loss Updated\n",
            "Epoch3 Training\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1250/1250 [01:06<00:00, 18.81it/s]\n",
            "100%|██████████| 313/313 [00:04<00:00, 74.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "에포크: 4, 손실: 1.33794, 정확도: 52.23%, 테스트 손실: 1.34464, 테스트 정확도: 52.34%\n",
            "✅ Model Loss Updated\n",
            "Epoch4 Training\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1250/1250 [01:06<00:00, 18.75it/s]\n",
            "100%|██████████| 313/313 [00:04<00:00, 74.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "에포크: 5, 손실: 1.27029, 정확도: 54.99%, 테스트 손실: 1.35855, 테스트 정확도: 51.41%\n",
            "Epoch5 Training\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1250/1250 [01:06<00:00, 18.73it/s]\n",
            "100%|██████████| 313/313 [00:04<00:00, 76.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "에포크: 6, 손실: 1.22500, 정확도: 56.61%, 테스트 손실: 1.29896, 테스트 정확도: 54.76%\n",
            "✅ Model Loss Updated\n",
            "Epoch6 Training\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1250/1250 [01:07<00:00, 18.63it/s]\n",
            "100%|██████████| 313/313 [00:04<00:00, 74.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "에포크: 7, 손실: 1.17627, 정확도: 58.72%, 테스트 손실: 1.31151, 테스트 정확도: 54.59%\n",
            "Epoch7 Training\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1250/1250 [01:07<00:00, 18.56it/s]\n",
            "100%|██████████| 313/313 [00:04<00:00, 74.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "에포크: 8, 손실: 1.13109, 정확도: 60.13%, 테스트 손실: 1.27864, 테스트 정확도: 55.67%\n",
            "✅ Model Loss Updated\n",
            "Epoch8 Training\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1250/1250 [01:12<00:00, 17.29it/s]\n",
            "100%|██████████| 313/313 [00:04<00:00, 74.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "에포크: 9, 손실: 1.08985, 정확도: 61.60%, 테스트 손실: 1.29929, 테스트 정확도: 55.83%\n",
            "Epoch9 Training\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1250/1250 [01:11<00:00, 17.51it/s]\n",
            "100%|██████████| 313/313 [00:04<00:00, 68.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "에포크: 10, 손실: 1.03721, 정확도: 63.62%, 테스트 손실: 1.30312, 테스트 정확도: 56.65%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Do not Touch!\n",
        "from tqdm import tqdm\n",
        "EPOCHS = 10\n",
        "min_loss = float(\"inf\")\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f\"Epoch{epoch} Training\")\n",
        "    for images, labels in tqdm(train_ds):\n",
        "        train_step(images, labels)\n",
        "        \n",
        "    for test_images, test_labels in tqdm(val_ds):\n",
        "        val_step(test_images, test_labels)\n",
        "\n",
        "    template = '에포크: {}, 손실: {:.5f}, 정확도: {:.2f}%, 테스트 손실: {:.5f}, 테스트 정확도: {:.2f}%'\n",
        "    print (template.format(epoch+1,\n",
        "                           train_loss.result(),\n",
        "                           train_acc.result()*100,\n",
        "                           val_loss.result(),\n",
        "                           val_acc.result()*100))\n",
        "    \n",
        "    if val_loss.result() < min_loss:\n",
        "        model.save_weights(\"./model.h5\")\n",
        "        print(\"✅ Model Loss Updated\")\n",
        "        min_loss = val_loss.result()\n",
        "    \n",
        "    train_loss.reset_states()\n",
        "    train_acc.reset_states()\n",
        "    val_loss.reset_states()\n",
        "    val_acc.reset_states()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "7qH17GaHIyF3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66058838-83a7-4855-e6b0-557e1fecd247"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 313/313 [00:06<00:00, 46.18it/s]\n"
          ]
        }
      ],
      "source": [
        "# Do not Touch!\n",
        "for test_images, test_labels in tqdm(test_ds):\n",
        "    test_step(test_images, test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "fX8mA9GMheGC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dd72794-da0a-4a58-c4cb-2589fb952997"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 56.22%\n"
          ]
        }
      ],
      "source": [
        "# Do not Touch!\n",
        "print(f\"Test Accuracy: {test_acc.result()*100:.2f}%\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "interpreter": {
      "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}