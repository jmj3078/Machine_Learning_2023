{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "xUBNg4SF0ukS"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "9RjCg3-i0x-Q"
   },
   "outputs": [],
   "source": [
    "# Do not Touch!\n",
    "class BasicBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, in_filters, out_filters, downsample=False):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.pad1 = tf.keras.layers.ZeroPadding2D((1,1))\n",
    "\n",
    "        self.relu = tf.keras.layers.ReLU()\n",
    "        self.conv2 = tf.keras.layers.Conv2D(out_filters, (3,3), strides=(1,1))\n",
    "        \n",
    "        self.batch_norm1 = tf.keras.layers.BatchNormalization()\n",
    "        self.batch_norm2 = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "        if downsample:\n",
    "            self.conv1 = tf.keras.layers.Conv2D(out_filters, (3,3), strides=(2,2))\n",
    "            self.downsample = tf.keras.layers.Conv2D(out_filters, (1,1), strides=(2,2))\n",
    "        else:\n",
    "            self.conv1 = tf.keras.layers.Conv2D(out_filters, (3,3), strides=(1,1))\n",
    "            self.downsample = None\n",
    "\n",
    "        if in_filters == out_filters:\n",
    "            self.channel_shaper = None\n",
    "        else:\n",
    "            self.channel_shaper = tf.keras.layers.Conv2D(out_filters, (1,1), strides=(1,1))\n",
    "\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        identity = inputs\n",
    "        out = self.pad1(inputs)\n",
    "        out = self.conv1(out)\n",
    "        out = self.batch_norm1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.pad1(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.batch_norm2(out)\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(inputs)\n",
    "        if self.channel_shaper is not None:\n",
    "            identity = self.channel_shaper(identity)\n",
    "\n",
    "        out += identity \n",
    "        out = self.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "SG_3VNPo01gg"
   },
   "outputs": [],
   "source": [
    "class ResNet18(tf.keras.Model):\n",
    "    def __init__(self, num_classes) -> None:\n",
    "        super(ResNet18, self).__init__()\n",
    "        self.pad3 = tf.keras.layers.ZeroPadding2D((3,3))\n",
    "        self.pad1 = tf.keras.layers.ZeroPadding2D((1,1))\n",
    "        self.conv1 = tf.keras.layers.Conv2D(64, kernel_size=(7,7), strides=(2,2))\n",
    "        self.pool = tf.keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2))\n",
    "        self.batch_norm = tf.keras.layers.BatchNormalization()\n",
    "        self.relu = tf.keras.layers.ReLU()\n",
    "\n",
    "        # 문제 1: BasicBlock을 활용하여, Convolution층을 정의하세요.\n",
    "        # Your Code Here!\n",
    "\n",
    "        # build_layer 함수를 통해서 각각 두번씩 BasicBlock을 쌓습니다.\n",
    "        # block b에서는 샘플의 크기가 변하지 않고, block c, d, e에서만 절반으로 줄어들어야 하기 때문에\n",
    "        # conv라는 옵션을 통해 downsampling block 추가 유무를 결정합니다.        \n",
    "        self.block_b = self.build_layers(64, 64, 2, conv=False)\n",
    "        self.block_c = self.build_layers(64, 128, 2, conv=True)\n",
    "        self.block_d = self.build_layers(128, 256, 2, conv=True)\n",
    "        self.block_e = self.build_layers(256, 512, 2, conv=True)\n",
    "\n",
    "        # 마지막 단계에서 Global Average Pooling 실시\n",
    "        self.Avgpooling = tf.keras.layers.GlobalAveragePooling2D()\n",
    "        # Fully connected layer형성을 위한 flatten()\n",
    "        self.flat = tf.keras.layers.Flatten()\n",
    "        # num_class수 만큼의 output 반환. 활성화 함수 softmax사용\n",
    "        self.dense = tf.keras.layers.Dense(num_classes, activation=\"softmax\")\n",
    "\n",
    "    def build_layers(self, in_filters, out_filters, num_blocks, conv=False):\n",
    "        # layer 리스트에 필요한 layer들을 append한 다음 한번에 tf.keras.Sequential로 레이어를 반환합니다.\n",
    "        layers= []\n",
    "        # conv 옵션이 활성화 될 경우에는 downsampling=True를 가장 첫 BasicBlock에서 활성시켜야 합니다.\n",
    "        # 활성화 될 시 stride의 크기가 2로 설정되어 샘플의 크기가 절반으로 줄어듭니다.\n",
    "        # 첫 BasicBlock의 경우 필터 크기의 변환도 실행해야 하기 때문에, in_filters와 out_filters를 입력값으로 줍니다.\n",
    "        if conv :\n",
    "            layers.append(BasicBlock(in_filters, out_filters, downsample=True))\n",
    "        else : \n",
    "            layers.append(BasicBlock(in_filters, out_filters, downsample=False))\n",
    "        # 두번째 블록부터는 in_filter와 out_filter의 크기가 같습니다.\n",
    "        # 따라서 out_filter값을 in_filter, out_filter에 넣어서 BasicBlock을 쌓습니다.\n",
    "        for i in range(num_blocks-1):\n",
    "            layers.append(BasicBlock(out_filters, out_filters, downsample=False))\n",
    "\n",
    "        # 쌓인 레이어들을 한번에 Sequential을 통해 반환합니다.\n",
    "        return tf.keras.Sequential(layers)\n",
    "\n",
    "    def call(self, x):\n",
    "        # 문제 2: 모델의 레이어를 정의하세요.\n",
    "        # Your Code Here!\n",
    "        out = self.conv1(x) # kernel size 7,7, strides=2, 샘플 크기가 절반으로 줄어듭니다. 64개의 채널을 가집니다.\n",
    "        out = self.pad3(out) # kernel size 3,3, zero padding\n",
    "        out = self.batch_norm(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.pool(out) # kenrel size 3,3 strides=2, 샘플 크기가 절반으로 줄어듭니다.\n",
    "        out = self.pad1(out) # kernel size 1,1 로 zero padding\n",
    "\n",
    "        out = self.block_b(out) # input channel 수 64, output channel 수 64\n",
    "        out = self.block_c(out) # input channel 수 64, output channel 수 128\n",
    "        out = self.block_d(out) # input channel 수 128, output channel 수 256\n",
    "        out = self.block_e(out) # input channel 수 256, output channel 수 512\n",
    "\n",
    "        out = self.Avgpooling(out) # global average pooling \n",
    "        out = self.flat(out) # flatten layer\n",
    "        out = self.dense(out) # Fully connected layer형성, num_class수 만큼의 output layer반환. 활성화 함수 softmax사용\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "SOEhuiMb04yl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"res_net18_30\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " zero_padding2d_288 (ZeroPad  multiple                 0         \n",
      " ding2D)                                                         \n",
      "                                                                 \n",
      " zero_padding2d_289 (ZeroPad  multiple                 0         \n",
      " ding2D)                                                         \n",
      "                                                                 \n",
      " conv2d_666 (Conv2D)         multiple                  9472      \n",
      "                                                                 \n",
      " max_pooling2d_30 (MaxPoolin  multiple                 0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_486 (Ba  multiple                 256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_258 (ReLU)            multiple                  0         \n",
      "                                                                 \n",
      " sequential_4 (Sequential)   (None, 10, 10, 64)        148736    \n",
      "                                                                 \n",
      " sequential_5 (Sequential)   (None, 5, 5, 128)         543488    \n",
      "                                                                 \n",
      " sequential_6 (Sequential)   (None, 3, 3, 256)         2168320   \n",
      "                                                                 \n",
      " sequential_7 (Sequential)   (None, 2, 2, 512)         8662016   \n",
      "                                                                 \n",
      " global_average_pooling2d_11  multiple                 0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         multiple                  0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            multiple                  5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,537,418\n",
      "Trainable params: 11,529,610\n",
      "Non-trainable params: 7,808\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Do not Touch!\n",
    "model = ResNet18(num_classes=10)\n",
    "model.build(input_shape=[None, 28,28,3])\n",
    "model.compile(optimizer='adam',\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "EPQClJoKIrZ4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "# Do not Touch!\n",
    "# Loss Function을 변수로 정의\n",
    "import tensorflow as tf\n",
    "\n",
    "loss_function = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "train_acc = tf.keras.metrics.CategoricalAccuracy()\n",
    "test_acc = tf.keras.metrics.CategoricalAccuracy() \n",
    "val_acc = tf.keras.metrics.CategoricalAccuracy() \n",
    "\n",
    "train_loss = tf.keras.metrics.Mean()\n",
    "test_loss = tf.keras.metrics.Mean()\n",
    "val_loss = tf.keras.metrics.Mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "E64I3o93juo7"
   },
   "outputs": [],
   "source": [
    "# Do not Touch!\n",
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(images)\n",
    "        loss = loss_function(labels, predictions)\n",
    "    \n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    train_loss.update_state(loss)\n",
    "    train_acc.update_state(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "GYtI4l9WHxqB"
   },
   "outputs": [],
   "source": [
    "# Do not Touch!\n",
    "@tf.function\n",
    "def test_step(images, labels):\n",
    "    predictions = model(images)\n",
    "    loss = loss_function(labels, predictions)\n",
    "    \n",
    "    test_loss.update_state(loss)\n",
    "    test_acc.update_state(labels, predictions)\n",
    "\n",
    "    return labels, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "YnMwUGY8L2nJ"
   },
   "outputs": [],
   "source": [
    "# Do not Touch!\n",
    "@tf.function\n",
    "def val_step(images, labels):\n",
    "    predictions = model(images)\n",
    "    loss = loss_function(labels, predictions)\n",
    "    \n",
    "    val_loss.update_state(loss)\n",
    "    val_acc.update_state(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "iGE22StzjzA7"
   },
   "outputs": [],
   "source": [
    "# Do not Touch!\n",
    "import math \n",
    "\n",
    "class generator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, x, y, batch_size, shuffle =True):\n",
    "        self.x = x.astype(np.float32)\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.x) / self.batch_size)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indices = np.arange(len(self.x))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        indices = self.indices[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        return self.x[indices], self.y[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "Xekl6vPhIyxG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170498071/170498071 [==============================] - 633s 4us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "# CIFAR-10 데이터셋 불러오기\n",
    "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
    "\n",
    "# 문제 3 (Optional): 정확도를 올리기 위한 데이터 전처리를 수행하셔도 됩니다.\n",
    "\n",
    "# 레이블을 범주형으로 인코딩\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "ZqJEfQfyHn2s"
   },
   "outputs": [],
   "source": [
    "# Do not Touch!\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_images, val_images, train_labels, val_labels = train_test_split(train_images, train_labels, test_size=0.2, random_state=10)\n",
    "\n",
    "train_ds = generator(train_images, train_labels, batch_size=32)\n",
    "val_ds = generator(val_images, val_labels, batch_size=32)\n",
    "test_ds = generator(test_images, test_labels, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bCKmzVzbhQME",
    "outputId": "5712faa6-4639-480a-ab6c-f38cd13d2fcf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch0 Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [04:17<00:00,  3.11it/s]\n",
      "100%|██████████| 200/200 [00:04<00:00, 47.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에포크: 1, 손실: 2.25666, 정확도: 30.91%, 테스트 손실: 1.65182, 테스트 정확도: 38.28%\n",
      "✅ Model Loss Updated\n",
      "Epoch1 Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [04:08<00:00,  3.22it/s]\n",
      "100%|██████████| 200/200 [00:03<00:00, 53.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에포크: 2, 손실: 1.56491, 정확도: 43.02%, 테스트 손실: 1.49243, 테스트 정확도: 45.38%\n",
      "✅ Model Loss Updated\n",
      "Epoch2 Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [03:54<00:00,  3.41it/s]\n",
      "100%|██████████| 200/200 [00:03<00:00, 57.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에포크: 3, 손실: 1.42826, 정확도: 48.32%, 테스트 손실: 1.45342, 테스트 정확도: 48.58%\n",
      "✅ Model Loss Updated\n",
      "Epoch3 Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [03:49<00:00,  3.48it/s]\n",
      "100%|██████████| 200/200 [00:03<00:00, 57.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에포크: 4, 손실: 1.31875, 정확도: 52.67%, 테스트 손실: 1.43946, 테스트 정확도: 48.98%\n",
      "✅ Model Loss Updated\n",
      "Epoch4 Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [03:41<00:00,  3.61it/s]\n",
      "100%|██████████| 200/200 [00:03<00:00, 58.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에포크: 5, 손실: 1.23622, 정확도: 55.32%, 테스트 손실: 1.52327, 테스트 정확도: 48.97%\n",
      "Epoch5 Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [03:41<00:00,  3.61it/s]\n",
      "100%|██████████| 200/200 [00:03<00:00, 53.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에포크: 6, 손실: 1.16483, 정확도: 58.25%, 테스트 손실: 1.47916, 테스트 정확도: 50.73%\n",
      "Epoch6 Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [03:49<00:00,  3.48it/s]\n",
      "100%|██████████| 200/200 [00:03<00:00, 56.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에포크: 7, 손실: 1.09790, 정확도: 60.89%, 테스트 손실: 1.51080, 테스트 정확도: 50.16%\n",
      "Epoch7 Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [03:44<00:00,  3.56it/s]\n",
      "100%|██████████| 200/200 [00:03<00:00, 61.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에포크: 8, 손실: 1.04227, 정확도: 63.03%, 테스트 손실: 1.48696, 테스트 정확도: 52.25%\n",
      "Epoch8 Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [03:39<00:00,  3.64it/s]\n",
      "100%|██████████| 200/200 [00:03<00:00, 53.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에포크: 9, 손실: 0.97591, 정확도: 65.54%, 테스트 손실: 1.65052, 테스트 정확도: 49.73%\n",
      "Epoch9 Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [03:46<00:00,  3.54it/s]\n",
      "100%|██████████| 200/200 [00:03<00:00, 57.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에포크: 10, 손실: 0.91895, 정확도: 67.34%, 테스트 손실: 1.60403, 테스트 정확도: 54.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Do not Touch!\n",
    "from tqdm import tqdm\n",
    "EPOCHS = 10\n",
    "min_loss = float(\"inf\")\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Epoch{epoch} Training\")\n",
    "    for images, labels in tqdm(train_ds):\n",
    "        train_step(images, labels)\n",
    "        \n",
    "    for test_images, test_labels in tqdm(val_ds):\n",
    "        val_step(test_images, test_labels)\n",
    "\n",
    "    template = '에포크: {}, 손실: {:.5f}, 정확도: {:.2f}%, 테스트 손실: {:.5f}, 테스트 정확도: {:.2f}%'\n",
    "    print (template.format(epoch+1,\n",
    "                           train_loss.result(),\n",
    "                           train_acc.result()*100,\n",
    "                           val_loss.result(),\n",
    "                           val_acc.result()*100))\n",
    "    \n",
    "    if val_loss.result() < min_loss:\n",
    "        model.save_weights(\"./model.h5\")\n",
    "        print(\"✅ Model Loss Updated\")\n",
    "        min_loss = val_loss.result()\n",
    "    \n",
    "    train_loss.reset_states()\n",
    "    train_acc.reset_states()\n",
    "    val_loss.reset_states()\n",
    "    val_acc.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7qH17GaHIyF3",
    "outputId": "6541d087-5847-4361-c5a0-9c11273f0740"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.38s/it]\n"
     ]
    }
   ],
   "source": [
    "# Do not Touch!\n",
    "for test_images, test_labels in tqdm(test_ds):\n",
    "    test_step(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fX8mA9GMheGC",
    "outputId": "e9340ecb-c1d8-4272-dd44-a7ac5f90907f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 56.25%\n"
     ]
    }
   ],
   "source": [
    "# Do not Touch!\n",
    "print(f\"Test Accuracy: {test_acc.result()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vt-z25ITGn3f"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "interpreter": {
   "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
